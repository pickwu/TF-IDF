*本文原创作者：mcvoodoo，本文属FreeBuf原创奖励计划，未经许可禁止转载
大数据安全保护思考
随着大数据时代的来临，企业数据开始激增，各种数据在云端、移动设备、关系型数据库、大数据库平台、pc端、采集器端等多个位置分散。对数据安全来说，挑战也更大了。在大型互联网企业里，传统方法已经很难绘制出一张敏感数据流转图了。因此在新的形势下，一是在工具层面要有新的手段支撑，包括完整的敏感数据视图、高风险场景识别、数据违规/滥用预警、数据安全事件的发现检测和阻止等。二是目前企业也存在着合规的问题了，以往合规对于互联网来说没那么重要，但随着网安法的出台，数据安全也摆上了日程。另外对于跨境企业来说，还面临着海外的数据安全法规。
所以，面临的挑战也是显而易见的。
1、 在策略层面：由于海量的数据类型，已经很难明确定义什么是高敏感数据了。同时也存在着多个低敏感数据关联后形成高敏感数据的普遍情况，甚至到最后，很难说清楚一个数据究竟有多少来源。而在一个大型互联网集团里，数据之间的交互也异常复杂，数据是否经过审批，下游如何使用也可能是混乱的。
2、 准确性：在混沌的组织结构、超级复杂且不断变化的系统里，要想实现数据安全的保护，其中一个重点是准确性的考虑。而准确性考虑按照现在的技术，也到了数据上下文、用户行为分析的阶段了，没有这些方法，误报将会很多甚至于不可用。
3、 及时性：很多业务都面临着迅速上线的压力，这时候安全就要能拿出一个快速低成本、可扩展的解决方案来，有些方法可能很土，有些方法可能需要人肉，但总体上衡量，应该是保护成本小于数据成本的可用解决方案。理想情况下，应该有工作流、机器学习、自动化来协助实现。
4、 可扩展性：也要考虑可扩展性，互联网行业里，说不准某个业务就突然爆发，原有的解决方案要能够对爆发后的架构进行支持，包括传统关系型数据库、大型数据仓库、云环境等。
还要多说一句，一个有理想的安全人员，不会止步于基础的保护能力，需要从不同项目中的经验提炼出更多价值和方法。任何数据保护方法，最后都应形成安全能力组件，为整体能力提供基础服务。按照国外某些公司的提法，应具备以API为驱动的安全能力。
业界也在不断探索新的方法来解决问题，forreste的报告，描述了这些年在数据安全上的各种防范的探索，假定大家都看得懂英文。
算了，我来解释下吧。横轴表示各技术的成长性，纵轴表示技术的价值。
红色这条线看起来是最失败的，既没有技术价值，也没有可以炒作的概念，分别对应了安全管理和企业权限管理。
灰色这条线上，有区块链、安全通信、应用层加密、密钥管理、数据分类、各种文件磁盘加密，再到DLP。这一部分价值还是有的，很多都已经成为企业标配技术，大家都耳熟能详，冷饭热炒也炒不出新花样了。
蓝色都是眼下炙手可热的技术，包括数据分类和flow mapping，数据隐私管理、数据主体权利管理、数据访问治理、大数据加密、令牌化技术、云数据保护。这一阶段的很多解决方案还在摸索实践中，相对于前面两条线，蓝色线技术更顺应大数据、云时代的潮流。
一、CASB（云安全接入代理）
CASB的出现是为了解决企业上云的问题，企业上云后，数据和业务系统都不在自己掌握中，为了保证企业的控制权，CASB出现了。在企业和云端之间部署一个代理网关，对上云的数据进行加密，反向则解密，这样保证了在云端的数据都是加密存储，防止未授权、黑客、云服务商获取数据。而负责加解密的KMS功能则独立管理。
粗暴一点的理解，可以认为是一些传统技术的合集，从功能上来说，一般包括DLP、身份认证、堡垒机、加解密。如果仅仅是这样，就成了一个UTM，也未免太没意思了。因此还有一些新技术也加入了进去，例如在身份认证上，还包括了基于设备、基于内容、基于应用的相关上下文理解的认证方式。同时也大量使用了机器学习算法在各模块中进行保护。
CASB解决的核心是上云的安全，从身份、权限、审计、防泄漏等角度出发。由于KMS的中立性，对于中小企业来说，算是一个可以接受的解决方案。但安全管理本质上是一个运营的管理，就像企业里之前买的各种安全产品，最终能否发挥作用，还依靠日常运维。
二、tokenization（令牌化）
tokenization最早应用于支付行业，将敏感数据（例如银行卡信息）替换成随机生成的数据，在替换之后，原始数据和令牌的映射关系单独存放在另一个数据库中。和加密不同的是，原始数据和随机数据之间没有数学关系，对于黑客来说，必须拿到映射关系表，才有可能拿到原始数据。
这样做的好处是，tokenization请求方可以不必存储银行卡信息，而只要存储随机数据即可，这样就不必记录银行卡信息，安全上消除了一些风险。而且他信息包括发卡行、有效日期等，也可以在随机数据中用若干字段实现。虽然这样风险聚集在了tokenization的服务方，但相对来说，服务方安全保障能力会更强一些。
这个技术用在互联网公司，也同样可以借鉴。我记得很早以前看到文章，谈到QQ的账号和密码保护，就是使用了这个方法，账号和密码分别存储，之间通过一个映射关系表来对应，这也是一种tokenization的用法。
除了账号和密码保护，也可以用在其他场景中。例如互联网企业可能存储了大量用户手机号、身份证号信息，通过tokenization，可以把数据形成一个新的随机数据，原始数据则加密存放。同时，可以对手机号相关信息建立一个纬度，例如标志运营商、地域信息，把这个字段放在随机数中，既满足了业务使用要求，也避免了相关人员接触到原始敏感数据。
Tokenization和Mask的区别也很简单，假设原始手机号是13911111111，Tokenization后变成13911112987，保持了运营商和归属地不变。而Mask后变成1391111****，后面四位不可见。当然mask也分为动态掩码和静态掩码，这里不做展开。
三、大数据加密
当大量数据被存放在Hadoop平台上的时候，这个大数据平台就成为了风险最集中的位置。Hadoop的生态系统核心是HDFS，从2.6版本开始HDFS支持原生静态加密，可以理解为一种应用层加密。
Hadoop生产集群通常都有成千上万的节点，把数据机密到HDFS之外的组件导致了很大的复杂性。另外，大规模加密还有一个难点是对于密钥的管理，要考虑速度和性能、对Hadoop的支持程度、管理难度问题。好消息是Rhino已经开源，在这之前对于数据的加密只能考虑全盘加密或文件系统加密。
另外，仅仅是对静态数据加密是不够的，数据在传输时的动态安全也需要加密，Hadoop有一堆的网络通信方式，RPC、TCP/IP、HTTP，对应到不同的动态加密方法。
够了么？还不够。综合起来来看，敏感数据不仅在HDFS上，还有各种与Hadoop交互的系统上，包括了mysql、oracle甚至临时文件、日志、元数据等各种地方。比如你要把线上生产数据库导入到大数据平台，在从源头到HDFS的通道中的加密也需要考虑，否则只要通过嗅探就可以获取。同样，在数据提取和客户端访问上，也需要考虑。
除了这些，还有其它让人头疼的各种数据应用场景，比如加密后的搜索、数据脱敏后的聚合隐私泄漏等等，现在都还在研究的概念上，无法落地。
所以目前，并没有一个完整视图的解决方案，因此需求很大，但能够提供完整方案的一个也没有。还需时日。
四、身份识别与访问管理
对敏感数据的位置、权限和活动的可视性管理，能够大规模自动化管理权限和数据，也即是IAM。这个概念出现很久了，之所以又被拿出来说，是因为一些新计入的加速融入，包括云身份管理、欺诈检测、UEBA、物联网、机器学习等技术。Gartner估计，到2022年，IAM的三分之一将由AI驱动。
在大型互联公司里，身份、权限、策略、资源、行为、设备，可能有几万亿的关系连接，这个世界上唯一不变的就是变化，这么多关系再加上实时动态的变化。如果不动用机器算法，是无法全面管理的。除了关系，IAM还涉及到和内部系统的多种集成，例如SOC、DLP、SSO等继承。
在新的思路下，可以把以前的场景用另外的方法关联表达出来。例如，以前的权限梳理，是把用户配置成不同的组，审查重点是用户的权限分配属否合理。在智能驱动下的权限管理，可以有很多不同，比如：张三有权访问一台服务器，他是这个部门中唯一有权限的人吗？又或者：张三整个部门都在访问一个共享文件夹，但只有李四是在周末访问的。再比如，有一个高敏感的数据，王二麻子和张三的使用率比其他人高出200%。某天，突然发现客服员工申请vpn急剧增加，调查发现，是由于当地大雪导致交通不畅，因此需要在家办公。这些具体问题在机器学习里，可以通过异常检测（或者是离散群分析）分析出来：某几个人和其他人的不同，从而形成对风险的判断。当风险点发现，可以通过调查来确认风险，然后再来调整算法。
因此，IAM在新技术的驱动下，会有一个更深刻的变化。
五、数据主体权限管理
之所以有这么个看起来很奇怪的数据主体权限管理，是由于欧盟GDPR（一般数据保护条例）的出台，GDPR规定了个人数据的权利，包括被遗忘的权利、删除权等等。这个条例会产生很大的市场，虽然是欧盟的，但所有和欧盟打交道的公司，都要遵从这一标准，否则会被罚款。看起来只是一个合规要求而已，但实际上在实际应用中，也有很多可借鉴的地方。
要保护个人数据，首先得知道这些数据都在哪，也就是数据发现的能力。可以通过对线上数据库抽样扫描、大数据仓库的元数据分析、dlp的本地扫描等来实现。但在实践中，还会有几个方面的问题。一是基于正则表达式的规则不靠谱，比如银行卡号这种信息，用正则表达式会产生大量的误报问题。二是在大数据平台的前提下，缺少快速准确的发现工具。三是很多数据都是非结构化的，比如个人交易金额，很难定义出一个规则。四是按照GDPR，还得有个可索引的系统，能够迅速从全量数据中找到某个人的信息数据元。
与这些问题相对应，机器学习可以解决的规则不准确、非结构化的问题，通过对上下文分析、语义理解、血缘关系追踪、元数据来提高。而通过在数据节点上分发搜索，能够全量感知敏感数据位置，再精细一点，可以使用敏感数据热力图进行预采样。
解决了数据发现的问题，还有数据的访问跟踪，每个业务、每个应用、每个用户对数据的访问，都要能跟踪到。说起来有点绕，举个例子，某客户投诉个人信息被泄漏，按照GDPR，你必须在72小时内作出响应动作来证明自己是清白的/有污点的。这时候你就要能够立刻知道，数据在哪里，在什么时间什么地点被谁访问过，然后根据这些上下游分析异常，完美的情况下，应该直接根据自动的风险规则来查出异常。
根据GDPR，你还要能够服从客户的意愿，假设客户要求你立刻删除所有与他相关的信息。这就需要强制性的响应措施，从不同节点修改/删除数据。
最后，通过一个类似于数据资产地图的形式，展现出来。
简单一点，可以把这个东西理解为数据资产地图或者数据态势感知这种dashboard，在下面有很多组件来支撑。
六、数据隐私管理解决方案
也基于整体的需求，出现这一类服务，帮助建设隐私管理。这不是一个技术，而是一个专项的数据安全风险评估。大体上来说，数据安全风险评估的几个阶段：建立团队—评估风险—设计和实施控制—维护和加强控制—合规性。
从GDPR的情况来看，未来企业可能需要一个“数据隐私保护官”的岗位，当然实际落地也可能是由信息安全来担任。这就在原来的信息安全上延伸更为广义了，隐私保护包括的环节很多，从数据采集到数据输出都有对应的环节存在，也比以前的信息安全范围更大。能否利用好GDPR来扩展安全部门在企业内部的影响力，是考验的时刻。
风险评估阶段，重点是围绕数据安全生命周期来开展。从关键岗位开始收集信息，包括了数据采集、存储、使用、转移、处理的环节。并且以数据和视觉形式记录信息，也就是数据移动的地图。通过风险评估识别出差距，并且根据优先级来考虑解决方案。
设计和实施阶段，对数据的保护，一定是从高敏感数据开始的。另外，对数据隐私的保护，在开展中可能会面临各种阻碍，这就要求数据安全部门能够有技巧的沟通，比如面向高管，这些数据的泄漏可能造成的后果，竞争对手从我们这里拿到了什么数据。面向技术部门，则可以列出竞争对手公司的对标，以及数据安全责任的归属。
而在维护和加强控制阶段，以国内的大型互联网企业来说，拍脑门就可以知道的风险域：系统变更、数据变更、国际业务、大型数据仓库、兼并收购、新增产品、高敏感数据管理、外包管理等，都是高风险区域。事实上很多公司在数据泄漏后，都无法追责，因为并不知道数据是从哪里泄漏出去的，因为根本不知道数据移动地图是怎样的。
合规性还是主要是指GDPR，定期评估、记录、合规性报告等。
目前国内来说，能帮助进行数据安全评估的公司并不多，设计出符合现状的低成本解决方案的更不多。随着国内对隐私立法的逐渐重视，这一块也会逐渐形成市场。
七、综述
forreste的报告中还提及了一些其他技术，在前面几块内容中我也陆陆续续提到了，包括数据发现、数据分类、企业级密钥管理、应用层加密这些内容。
对数据安全的综合治理，核心思路其实就是一个：数据流动地图，抓住这条主线，也就是以数据为核心的安全保护。大数据时代，基于边界的方法已经过时了，你无法阻挡数据的流动。而在新的时代，还有很多未能解决的难题，换句话说，作为一个安全人员，你是在挖洞的如云高手中杀出一条血路，还是在这个需要探索的领域做先头兵？
*本文原创作者：mcvoodoo，本文属FreeBuf原创奖励计划，未经许可禁止转载