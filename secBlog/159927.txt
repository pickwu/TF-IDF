一、爬虫简介
根据百度百科定义：网络爬虫（又被称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。 随着大数据的不断发展，爬虫这个技术慢慢走入人们的视野，可以说爬虫是大数据应运而生的产物，至少我解除了大数据才了解到爬虫这一技术
二、几种适合爬虫的语言
1.phantomjs
这个语言在17年4月其开核心发者之一Vitaly辞退维护工作，表示不再维护。其原话内容如下：
我看不到 PhantomJS 的未来，作为一个单独的开发者去开发 PhantomJS 2 和 2.5 ，简直就像是一个血腥的地狱。即便是最近发布的 2.5 Beta 版本拥有全新、亮眼的 QtWebKit ，但我依然无法做到真正的支持 3 个平台。我们没有得到其他力量的支持！
并且Vitaly 发文表示，Chrome 59 将支持 headless 模式，用户最终会转向去使用它。Chrome 比 PhantomJS 更快，更稳定，也不会像 PhantomJS 这种疯狂吃内存 但并不是意味着这个语言的终结，这个语言还是可以用的
2.casperJS
CasperJs 是一个基于 PhantomJs 的工具，其比起 PhantomJs 可以更加方便的进行 navigation，个人对此种语言不太了解不做过多阐述
3.nodejs
nodejs适合垂直爬取，分布式的爬取较为困难，对某些功能的支持较弱，所以不建议用
4.Python
本人喜欢python这种语言，也是强烈推荐使用python，尤其是其语言的爬虫框架scrapy特别值得大家学习，支持xpath 可以定义多个spider，支持多线程爬取等等，后续我会一步一步把我入门的过程发给大家并且附带源码
ps：此外还有c++,PHP,java等语言都可以用来爬取网页，爬虫因人而异，我推荐的不一定是最好的
三、python爬虫的优点
代码简单明了，适合根据实际情况快速修改代码，网络上的内容，布局随时都会变，python的快速开发比较有优势。如果是写好不再修改或修改少，其他性能高的语言更有优势。（摘自知乎https://www.zhihu.com/question/52081407）
1）抓取网页本身的接口相比与其他静态编程语言，如java，c#，C++，python抓取网页文档的接口更简洁；相比其他动态脚本语言，如perl，shell，python的urllib2包提供了较为完整的访问网页文档的API。（当然ruby也是很好的选择）此外，抓取网页有时候需要模拟浏览器的行为，很多网站对于生硬的爬虫抓取都是封杀的。这是我们需要模拟user agent的行为构造合适的请求，譬如模拟用户登陆、模拟session/cookie的存储和设置。在python里都有非常优秀的第三方包帮你搞定，如Requests，mechanize
2）网页抓取后的处理抓取的网页通常需要处理，比如过滤html标签，提取文本等。python的beautifulsoap提供了简洁的文档处理功能，能用极短的代码完成大部分文档的处理。（摘自博客园https://www.cnblogs.com/benzone/p/5854084.html）
以上是前辈们为我们归纳好的诸多优点，本人整理其中两篇供大家参考
四、后续的安排
后续我会给大家分享以下内容